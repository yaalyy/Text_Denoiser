{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25af6543-6667-473f-b3d7-5fc70cbad3fe",
   "metadata": {},
   "source": [
    "Importings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89517f6e-ce34-47e8-9f0c-37d290e6b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn import datasets as skdataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from IPython.display import Video\n",
    "\n",
    "from torchvision import models, transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f428eb8-b645-42ca-b1d6-a507c8ff2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataset used to import and export data \"\"\"\n",
    "class DenoisingDB(Dataset):\n",
    "\n",
    "    def __init__(self, input_imgs_path, cleaned_imgs_path):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_imgs_path = input_imgs_path\n",
    "        self.cleaned_imgs_path = cleaned_imgs_path\n",
    "        self.input_images = sorted(os.listdir(input_imgs_path))\n",
    "        self.cleaned_images = sorted(os.listdir(cleaned_imgs_path))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        length = len(self.input_images)\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_img_path = os.path.join(self.input_imgs_path, self.input_images[idx]) # single image path\n",
    "        cleaned_img_path = os.path.join(self.cleaned_imgs_path, self.cleaned_images[idx])\n",
    "\n",
    "        input_img = Image.open(input_img_path).convert(\"RGB\")\n",
    "        cleaned_img = Image.open(cleaned_img_path).convert(\"RGB\")\n",
    "\n",
    "        # crop the image\n",
    "        input_img = input_img.crop((0,0,128,128))\n",
    "        cleaned_img = cleaned_img.crop((0,0,128,128))\n",
    "\n",
    "        # convert image to pytorch tensor\n",
    "        input_img = torch.from_numpy(np.array(input_img)).permute(2,0,1).float() / 255.0\n",
    "        cleaned_img = torch.from_numpy(np.array(cleaned_img)).permute(2,0,1).float() / 255.0\n",
    "\n",
    "\n",
    "        return (input_img, cleaned_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbd8c9-873e-489a-9b82-54a68e13e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingCNN, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # (64, 128, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # (128, 128, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # (256, 128, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (256, 64, 64)\n",
    "        )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # (256, 64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),  # (128, 64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # (128, 32, 32)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2),  #(128, 64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),  # (64, 128, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),   # (3, 128, 128)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40003fe5-1bb4-4f5d-b412-87f52f79da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the network\n",
    "model = DenoisingCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32891f-6fd3-43ca-b306-026d5aa5e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prediction, target):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error (MSE) loss between the prediction and the target.\n",
    "\n",
    "    Arguments:\n",
    "    prediction : torch.Tensor\n",
    "        The predicted image.\n",
    "    target : torch.Tensor\n",
    "        The target image for reconstruction.\n",
    "\n",
    "    Returns:\n",
    "    loss : torch.Tensor\n",
    "        The computed loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # MSE loss\n",
    "    loss = torch.mean((prediction - target) ** 2)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e2d38-cd52-4668-963e-93ce3fa0914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./data/\"\n",
    "\n",
    "input_imgs_path = os.path.join(dataset_path,\"input_noisy_images/\")\n",
    "cleaned_imgs_path = os.path.join(dataset_path,\"target_clean_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4536fe0-f577-431e-a6c6-8e77def11795",
   "metadata": {},
   "source": [
    "Training part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0023c-fa7c-433e-9215-58e670e3f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "num_epochs = 100\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # try to use cuda acceleration\n",
    "\n",
    "# load data\n",
    "dataset = DenoisingDB(input_imgs_path, cleaned_imgs_path)\n",
    "\n",
    "# split dataset into training and testing\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "test_size = len(dataset) - train_size  # 20% test\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimiser\n",
    "\n",
    "\n",
    "# set model to training mode\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#Training\n",
    "print(f\"------Training Started------\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for (batch_idx, (input_img, cleaned_img)) in enumerate(train_loader):\n",
    "        input_img, cleaned_img = input_img.to(device), cleaned_img.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        output = model(input_img)\n",
    "        loss = loss_function(output, cleaned_img)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # evaluate model every 10 epoch\n",
    "    if (epoch+1) %10 == 0:\n",
    "        model.eval()  \n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():  \n",
    "            for input_img, cleaned_img in test_loader:\n",
    "                input_img, cleaned_img = input_img.to(device), cleaned_img.to(device)\n",
    "                output = model(input_img)\n",
    "                loss = loss_function(output, cleaned_img)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {avg_test_loss:.4f}\")\n",
    "        model.train()  # set back to training mode\n",
    "print(f\"------Training Completed------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19f8bb-25b0-49c6-b96e-c8c3ff3c7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models/\"):\n",
    "  os.makedirs(\"./models/\")\n",
    "torch.save({\"denoiser\":model}, \"models/denoiser.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1be50-59c8-450c-8c59-ee19390c6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # try to use cuda acceleration\n",
    "state_dict = torch.load(\"models/denoiser.pth\")\n",
    "denoiser = state_dict[\"denoiser\"].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a4e79-e1dc-441b-9018-f931a1b4b9c4",
   "metadata": {},
   "source": [
    "Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af721a72-ad9c-4c5b-aa6d-95d2fb72ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgs, gt_imgs, output_imgs = [], [], []\n",
    "\n",
    "\n",
    "denoiser.eval()\n",
    "denoiser.to(device)\n",
    "\n",
    "# model.eval()\n",
    "# model.to(device)\n",
    "dataset = DenoisingDB(input_imgs_path, cleaned_imgs_path)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "  for idx, (input_img, gt_img) in enumerate(dataloader):\n",
    "    if idx >= 5:\n",
    "      break\n",
    "\n",
    "    input_img, gt_img = input_img.to(device), gt_img.to(device)\n",
    "    output_img = denoiser(input_img)\n",
    "    # output_img = model(input_img)\n",
    "    input_imgs.append(input_img[0].cpu().permute(1,2,0).numpy())\n",
    "    gt_imgs.append(gt_img[0].cpu().permute(1,2,0).numpy())\n",
    "    output_imgs.append(output_img[0].cpu().permute(1,2,0).numpy())\n",
    "\n",
    "\n",
    "titles = ['Input', 'GroundTruth', 'Output']\n",
    "plot_images_with_text([input_imgs, gt_imgs, output_imgs],titles,texts=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
